[{"id":0,"href":"/erp/docs/table-of-contents/training/part_1/","title":"1. Getting started with ERPLAB","section":"ERP Training Resources","content":"\nGetting started (or \u0026lsquo;help, how do I make ERPLAB work?\u0026rsquo;)\r#\rIntro\rTo conduct any of the analyses featured in this tutorial, you require three downloads.\nFirstly, MATLAB. MATLAB is a very powerful (see also \u0026lsquo;very expensive\u0026rsquo;) software programme. However, in order to use EEGLAB MATLAB is a pre-requisite. Luckily however they offer some pretty great discounts for students, so it\u0026rsquo;s well worth buying a student copy if that\u0026rsquo;s a possibility. Universities will also often have a MATLAB license that you\u0026rsquo;ll be able to use either on campus, or link to via your personal computer.\nNext, you\u0026rsquo;ll need to download EEGLAB. EEGLAB is super handy open-access software intended for research purposes. EEGLAB is a necessary pre-requisite to ERPLAB, with which we\u0026rsquo;ll conduct most of our pre-processing.\nSteps: Download EEGLAB from the above link. Extract the folder, then open MATLAB. Navigate to \u0026lsquo;set path\u0026rsquo;, which you can find in the Home tab in the Environment section. Select \u0026lsquo;Add Folder\u0026rsquo; and navigate to the EEGLAB folder. You may then wish to select EEGLAB in the \u0026lsquo;MATLAB search path\u0026rsquo; list and move it to the top, with the help of the \u0026lsquo;Move to top\u0026rsquo; button on the left-hand side. For more details, click here\nFinally, you will need to download the ERPLAB toolbox, some more great open-access software that will enable you to conduct pretty much any pre-processing operation you could want. To learn more about ERPLAB, have a read through this article by Lopex-Calderon \u0026amp; Luck.\nSteps: Download ERPLAB from the above link. Extract the folder, Then place the extracted ERPLAB folder into your EEGLAB plugins folder.\n(e.g., C:/Users/Jen/Documents/MATLAB/eeglab2022.0/plugins/)\nN.B I am in no way affiliated with any of the above mentioned companies/products/resources. I gain no financial incentives for providing the links here or if you click on them, but have done so to make things a little easier to find.\n"},{"id":1,"href":"/erp/docs/table-of-contents/","title":"About","section":"Docs","content":"\nThe resources on these pages are predominantly intended for use by undergraduate, postgraduate, and PhD students wishing to learn to use the powerful (yet initially complex) EEGLAB and ERPLAB software for data pre-processing. The website is owned \u0026amp; maintained by Jen Lewendon, postdoctoral researcher at New York University Abu Dhabi.\nWhilst a myriad of resources are available for the novice ERP researcher, the information on this website aims to fill a gap. Firstly, the ERP Training Resources pages aim to provide a full tutorial from instillation of EEG \u0026amp; ERP lab, to UI or script-based pre-processing and analysis. This should support the user with no prior MATLAB or EEGLAB/ERPLAB experience to get started with EEG data pre-processing. The course also offers practice datasets, scripts, and other resources to consolidate learning and allow for hands-on practice of the full pre-processing pipeline without the need for the user to acquire or source their own data. The course is particularly geared to support Mandarin speaking students to familiarise themselves with the often complex terminology and concepts of pre-processing, offering a wealth of translated content.\nSecondly, the External Resources \u0026amp; Publications section of this website provides a repository of key literature to guide the learner through every stage of the ERP research process, from experiment design, data acquisition, pre-processing \u0026amp; analysis, and reporting. I do claim any ownership of these resources, but find them very useful in my own research.\nThirdly, the Resources for Researchers section features a number of databases and tools that may prove useful for ERP researchers conducting research into auditory ERP responses. This comes from my own work, and is mostly unpublished resources.\nFinally the Teaching Material section combines both my own materials and external content to help design course content at tertiary level for ERP studies.\nYou are free (in fact, welcome) to use all and any of the resources on this site. Some are owned by me, and some (e.g., the external publications folder) are owned by others. For use of publications linked within this website, please ensure you follow the appropriate citation format as specified on the individual websites/articles etc. Everything else on this site, is released under a CC-BY license, which means you can do anything you want with these materials and can change/adapt them in any way you like, as long as you acknowledge that you got it from here.\nPlease do share the website with anyone for whom the resources might be useful. For any enquiries, help, or further information, contact Jen via her personal website here.\n"},{"id":2,"href":"/erp/docs/table-of-contents/external/design/","title":"Designing your study","section":"External Resources \u0026 Publications","content":" Thinking about your design\r#\rDesigning you study is a key element of ERP research design. Multiple considerations can guide your design to ensure that valuable time spent acquiring, pre-processing and analysing data produces valuable (and hopefully publishable) results.\rWhilst I list a number of resources here, one main considerations that most ERP research overlooks one important principle. Termed the Hillyard Principle (see Luck, 2014), by Steve Luck, the basic premise that ERP responses should be elicited by stimuli that are - in principle - physically identical. Many ERP studies violate this principle, mostly because it is usually far easier to create stimuli that do not adhere to it.\nI want to run a study that examines how people respond to words that are related vs unrelated (see this article if you\u0026rsquo;re unsure which component this experiment might study). Below are examples of my stimuli:\nPrime Target\nRelated: dog cat\nUnrelated: apple garage\nHere, my targets (which I\u0026rsquo;ll measure my ERP response to) are physically different. This introduces a potential secondary factor that might influence any results I find. Instead of being able to attribute any differences in my ERPs to related vs unrelated words, it\u0026rsquo;s very possible that a host of features (including the word length, orthography, frequency\u0026hellip; etc. etc.) might actually be the driving force behind any differences I find. Instead I could improve my design as follows:\nPrime Target\nRelated: dog cat\nUnrelated: apple cat\nNow my ERPs are elicited by the word cat in both conditions, meaning that any physical differences between the conditions must arise purely from their relationship to the prime.\nThe Hillyard Priciple is by no means the only thing to consider in your design, but is a key design issue that necessitates further attention than it is typically afforded. Other important literature\r#\rGeneral design\r#\rPicton, T. W., Bentin, S., Berg, P., Donchin, E., Hillyard, S. A., Johnson Jr, R., \u0026hellip; \u0026amp; Taylor, M. J. (2000). Guidelines for using human event‐related potentials to study cognition: Recording standards and publication criteria.\nOptimising your paradigm for a given component\r#\rKappenman, E. S., Farrens, J. L., Zhang, W., Stewart, A. X., \u0026amp; Luck, S. J. (2021). ERP CORE: An open resource for human event-related potential research. NeuroImage, 225, 117465.\nSample size \u0026amp; power\r#\rPolitzer-Ahles (unpublished) ERP power analyzer.\nClayson, P. E., Carbine, K. A., Baldwin, S. A., \u0026amp; Larson, M. J. (2019). Methodological reporting behavior, sample sizes, and statistical power in studies of event‐related potentials: Barriers to reproducibility and replicability. Psychophysiology, 56(11), e13437.\nLarson, M. J., \u0026amp; Carbine, K. A. (2017). Sample size calculations in human electrophysiology (EEG and ERP) studies: A systematic review and recommendations for increased rigor. International Journal of Psychophysiology, 111, 33-41.\nMisuse of null-hypothesis testing for nuisance effects\r#\rSassenhagen, J., \u0026amp; Alday, P. M. (2016). A common misapplication of statistical inference: Nuisance control with null-hypothesis significance tests. Brain and language, 162, 42-45.\n"},{"id":3,"href":"/erp/docs/table-of-contents/training/","title":"ERP Training Resources","section":"About","content":" The following pages are intended to form a complete course for beginners on ERP pre-processing and analysis in MATLAB. The course assumes no prior knowledge of MATLAB or ERPLAB, but does require a basic understanding of EEG/ERP data and pre-processing stages. The steps here follow guidelines for optimal ERP pre-processing steps in the order sppecified by Luck \u0026amp; Kappenman, taking into consideration the important concept of linear and non-linerar operations.\nThe course is split into X parts. Each part is intended to only last a couple of minutes, allowing you to dip in and out as required. The format is (mostly) consistent aross each parts as follows:\nA brief description of the pre-processing operations; A video to guide you through conducting the pre-processing operation(s) via the user interface (UI); The code equivalent of the pre-processing steps conducted; A complete script, compiles all pre-processing operations conducted up to (and including) the current page; An example dataset (so that you can have a go); Where relevant, a brief activity or task to consolidate understanding. FAQs "},{"id":4,"href":"/erp/docs/table-of-contents/training/part_2/","title":"2. Importing data","section":"ERP Training Resources","content":"\nImporting data (or \u0026lsquo;help, how do I get started?\u0026rsquo;)\r#\rIntro\rNow you\u0026rsquo;ve got ERPLAB up and running, it\u0026rsquo;s time to have a look at some data! But how do you get your data into ERPLAB in the first place? Take a look at the video below for a brief guide to the process of importing your data.\nVideo\rCode EEG = pop_loadcnt('C:\\[DATASET ADDRESS]\\[DATASET NAME].cnt' , 'dataformat', 'auto', 'memmapfile', ''); [ALLEEG EEG CURRENTSET] = pop_newset(ALLEEG, EEG, 0,'setname','[DATASET NAME FOR ERPLAB]','gui','off'); Script Script #1 (download).\nScript #1 (view).\nDataset To run this operation via the user interface, the example data set (used in the above video) can be downloaded here.\nActivity\rHave a go at importing Dataset #1 into EEGLAB using both the user interface and script methods. For the script method, try saving Dataset_1 (e.g., Dataset_1, Data_set2) with a different name, and see if you can import multiple datasets using the Script 1. Finally, save your version of the script (with all the amended folder paths) to your computer so as to ensure you have a working script for subsequent tutorial sections (and your own data analysis!).\nFAQs\rWhy won\u0026#39;t my dataset load?\r↕\rEnsure that you are attempting to import the correct file type. Remember that the instructions here are for .CNT file types, but the steps themselves transferable across a range of file types.\rMy dataset isn\u0026#39;t in any of the listed formats. What should I do?\r↕\rMost data acquisition software offers the ability to convert your file type. For example, I use software that produces a range of files that are incompatible with EEGLAB. However, I am able to save these files in a compatible format within the acquisition software. If you\u0026rsquo;re unsure of how to do this, speak to your EEG technician, researchers around you, or (always a decent resort), Google.\rI tried to run the script but it didn\u0026#39;t work. Help!\r↕\rEnsure you\u0026rsquo;ve read the Scripts: Essential information page, which provides further information on the file and folder structures necessary to run scripts available on this site. Always check that your path to the experiment folder and EEGLAB are correct\r"},{"id":5,"href":"/erp/docs/table-of-contents/external/acquisition/","title":"Acquiring your data","section":"External Resources \u0026 Publications","content":"Coming soon! Acquiring your data\r#\r"},{"id":6,"href":"/erp/docs/table-of-contents/external/","title":"External Resources \u0026 Publications","section":"About","content":" The use of ERP methodology involves numerous degrees of freedom. To ensure the reliability and replicability of ERP research output, it is therefore crucial that researchers avoid practises (all too common to the field) prone to result in erroneous effects, and ensure that their reporting is complete and replicable. To support researchers to do so, numerous efforts have been made to improve how people use ERP as a methodology, and ensure that reporting of data acquisition, pre-processing, analyses, and results are standardised. Such tools, frameworks, and guidance harbour the potential to substantially increase replicability and reliability in the field, and tackle the ongoing replication crisis.\nThese resources provide us with an invaluable opportunity to substantially improve standards in ERP research and reporting. As the field continues to expand, the implementation of these guidelines and recommendations in ERP study design, data collection, analysis, and reporting is crucial to ensure the reliability and validity of scientific developments. However, despite the longstanding availability of such resources, their use (and adherence to their guidance) is scarce (see, for example. common under-reporting of methodological detail; infrequent use of sample size calculations).\nThe literature cited within these serves as a repository for resources that can guide every stage of your ERP research through design, data acquisition, pre-processing, and reporting to ensure that the research you produce make a valuable contribution to the field.\nNB. It goes without saying that the first resource for any ERP researcher in the making is An Introduction to the Event-Related Potential Technique by Steve Luck. If finances are of concern (which, of course, for most students it is) consider the first edition, which contains much of the useful content and can be sourced second-hand for quite a bit less.\n"},{"id":7,"href":"/erp/docs/scripts/","title":"Scripts: Essential information","section":"Docs","content":"\rHow to use the scripts provided within these pages\r#\rEvery script looks a little different to the \u0026lsquo;code\u0026rsquo; line on the website. The reson for this is that the code is intended to enable you to identify what the pre-processing operation looks like in code form and to create your own scripts, whilst the scripts provided are intended to make your pre-processing more efficient, allowing you to run each pre-processing operation on all your datasets at once. This requires a little more info (i.e., where EEGLAB is stored on your computer, etc.), and therefore means that a couple of steps are necessary before you can use the scripts for your own data.\nPrepare your data files\r#\rAll the scripts features on this website require that your data is stored as follows.\nFirst, you must create a folder specifically for your experiment.\nThen you must create individual folders for each participant, with the name of the datasets matching the name of the folder exactly.\nFinally, you must ensure that all data from that participant is stored within this folder. This includes .CNT files, .fdt and .set files, and behavioural data.\nNext, you can start to tell you script where the necessary folders are on your computer in order to run. At the beginning of each script, the following will almost always be necessary:\nExample script (download).\nExample script (view).\nEnsure that for every script you run from this site, you enter the correct information as outlined in the example scripts above.\nN.B. The scripts on this website could not have been produced without the valuable guidance and help that I received from Dr. Politzer-Ahles (Kansas University) throughout my first postdoc.\n"},{"id":8,"href":"/erp/docs/table-of-contents/training/part_3/","title":"3. Setting channel locations","section":"ERP Training Resources","content":"\nChannel locations\r#\rIntro\rSo you\u0026rsquo;ve got your data open. But the problem is, EEGLAB has no idea which channel goes where. At present, all it knows is your channel IDs (names/numbers) if you\u0026rsquo;re lucky. So your next step is to tell EEGLAB where these channels belong in relation to one another by using a location file. Luckily, the creators of EEGLAB have provided a channel file which features a database of 385 defined channel labels. As long as your data was imported into EEGLAB with these labels (which most systems do) then sourcing your channel locations from this file should typically work well.\nVideo\rCode EEG=pop_chanedit(EEG, 'lookup',[pathtoeeglab '\\\\plugins\\\\[CHANNEL ADDRESS]]']);\rScript\rScript #2 (download).\nScript #2 (view).\nDataset To run this operation via the user interface, the example data set (used in the above video), along with the channel location file can be downloaded here.\nActivity\rHave a go at setting channel locations for your dataset using both the UI and the scripts provided.\nFAQs\rHow do I delete a channel?\r↕\rFirstly, have a think. Why might you want to do this? Perhaps your EEG system has recorded a channel that wasn\u0026rsquo;t intended (i.e., EKG), or you selected a layout during data recording for one participant that includes electrodes not present in your other datasets (making it difficult to grand average across datasets with different numbers of channels at a later stage). Most of the time it is not necessary to manually remove a channel unless there is a discrepancy between the number of channels present across datasets. However, if this is the ase, simply selecting \u0026lsquo;delete channel\u0026rsquo; on the edit channel info menu will not remove the channel from a dataset. Instead, you should go to Edit\u0026gt;Select data\u0026gt;Channel range, and by ticking the \u0026lsquo;remove these\u0026rsquo; checkbox can select any channels you wish to remove.\n\u0026lt;/div\u0026gt;\r"},{"id":9,"href":"/erp/docs/table-of-contents/external/preprocess/","title":"Pre-processing \u0026 analysis","section":"External Resources \u0026 Publications","content":" Pre-processing \u0026amp; analysis\r#\rPerhaps the second major time investment in any ERP study is the preprocessing that must occur subsequent to data acquisition, before you can even begin to analyse or interpret your data. However, this is where degrees of experimenter freedom increase substantially, resulting in practices that are either intentionally or unintentionally less than ideal. In addition to this, the analyses you choose (and how you choose them) require considerable thought. Below, I have outlined just a few considerations.\nThe problem of multiple implicit comparisons\r#\rOne of the most widely accepted/practiced techniques in ERP data analysis (but importantly, one that is also widely accepted to be flawed) is the selection of time windows and electrodes in order to calculate mean/peak amplitude by looking at where an effect seems to happen. This might seem like an intuitive process, but the implications for the validity of any results that follow from it are considerable. For an excellent paper on See this article by Luck and Gaspelin (2017)\nPreprocessing \u0026amp; analysis\r#\rKeil, A., Debener, S., Gratton, G., Junghöfer, M., Kappenman, E. S., Luck, S. J., \u0026hellip; \u0026amp; Yee, C. M. (2014). Committee report: publication guidelines and recommendations for studies using electroencephalography and magnetoencephalography. Psychophysiology, 51(1), 1-21\nFiltering (and what inappropriate filtering can do to your data)\nTanner, D., Morgan‐Short, K., \u0026amp; Luck, S. J. (2015). How inappropriate high‐pass filters can produce artifactual effects and incorrect conclusions in ERP studies of language and cognition. Psychophysiology, 52(8), 997-1009.\n"},{"id":10,"href":"/erp/docs/table-of-contents/training/part_4/","title":"4. Resampling","section":"ERP Training Resources","content":"\nResampling\r#\rIntro\rResampling is a (relatively) simple process that can basically be thought of as deciding how much detail you want to retain in your dataset. Usually, this decision comes down to two things:\nHow important is it for you to measure the precise onset of your effects? Typically, I want to know roughly when my effects begin and end. By reducing the sampling rate I lose a little bit of this information, but not a huge amount. For example, by resampling my data down to 250 Hz I introduce an error of ±2 ms. This is fine for the research I do, but if you\u0026rsquo;re interested in super precise comparisons of the onset of an effect for which 2 ms error would be problematic, you\u0026rsquo;ll want to keep your sampling rate higher. However, this brings us to the next consideration\u0026hellip;\nHow much space do you have on your computer? EEG datasets are typically quite big. Usually you need a reasonable number of them. If you want to run two studies that are both about an hour long, with 40 participants for each and to keep you data at a sampling rate of 1000 Hz, you\u0026rsquo;re going to quickly use up a lot of space on your computer. Beyond this, your pre-processing is going to take longer. For simple things such as re-referencing your sampling rate won\u0026rsquo;t make much difference, but for more complex processes such as artifact correction, the increase in time can be quite significant. If you can afford to lose a little bit of temporal resolution, it\u0026rsquo;s usually worthwhile resampling to a lower rate.\nVideo\rCode\nEEG = pop_resample( EEG, 250);\rScript\nScript #3 (download).\nScript #3 (view).\nNote that to run this script you should use Dataset #1 in its original .CNT form, as the script runs from the original continuous files (you need a different function to import .fdt and .set EEGLAB files)\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here.\nActivity\nHave a go at resampling the dataset provided, both via the user interface and using the available script. Finally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nCan I resample to a different sampling rate than 250 Hz?\r↕\rFor most experiments, a sampling rate of somewhere between 200 - 1000 Hz is ok. Lower sampling rates will mean that your data files are smaller, and processes steps such as ICA run faster. Higher sampling rates make your datasets larger, but give you more fine-grain detail, which can be particularly useful if you want to explore the latency of a response.\r"},{"id":11,"href":"/erp/docs/table-of-contents/researcher_resources/","title":"Resources for researchers","section":"About","content":"under construction\nPre-processing reporting template\nA generic template for reporting ERP pre-processing steps. Note that this template will not suit everyone, and adaptation/amendments/deletions may be required Template for reporting\n"},{"id":12,"href":"/erp/docs/table-of-contents/teaching/","title":"Teaching Material","section":"About","content":"under construction\n"},{"id":13,"href":"/erp/docs/table-of-contents/external/writing/","title":"Writing your paper","section":"External Resources \u0026 Publications","content":" Writing your paper\r#\rReporting\r#\rKeil, A., Debener, S., Gratton, G., Junghöfer, M., Kappenman, E. S., Luck, S. J., \u0026hellip; \u0026amp; Yee, C. M. (2014). Committee report: publication guidelines and recommendations for studies using electroencephalography and magnetoencephalography. Psychophysiology, 51(1), 1-21\nPicton, T. W., Bentin, S., Berg, P., Donchin, E., Hillyard, S. A., Johnson Jr, R., \u0026hellip; \u0026amp; Taylor, M. J. (2000). Guidelines for using human event‐related potentials to study cognition: Recording standards and publication criteria\n"},{"id":14,"href":"/erp/docs/table-of-contents/training/part_5/","title":"5. High-pass filtering","section":"ERP Training Resources","content":"\nHigh-pass filtering\r#\rIntro\nFiltering is a complex process, and requires some thought and consideration. It\u0026rsquo;s important that you read the literature on filtering to understand what you are doing to your data, and the consequences of inappropriate filtering.\nVideo\nComing soon\r#\rCode\nEEG = pop_basicfilter( EEG, [1:NUMBER OF ELECTRODES] , 'Boundary', 'boundary', 'Cutoff', 0.1, 'Design', 'butter', 'Filter', 'highpass', 'Order', 2 ); Script\nScript #4 (download).\nScript #4 (view).\nNote that to run this script you should use Dataset #1 in its original .CNT form, as the script runs from the original continuous files (you need a different function to import .fdt and .set EEGLAB files)\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nHave a go at applying the filters both via the UI and with the provided script on Dataset_1. Play around with different filter settings and have a look at what different slops and thresholds do to the data. Once you\u0026rsquo;ve done this, be sure to read through the Template for ERP Pre-processing Reporting here (download), and try to fill in the gaps to report the necessary information about the high-pass filter you\u0026rsquo;ve applied to your data. Finally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nI\u0026#39;ve heard the terms \u0026#39;online filter\u0026#39; and \u0026#39;offline filter\u0026#39;. What do these mean?\r↕\rOffline filters refer to pre-processing steps taken subsequent to data acquisition. Online filters are those applied during EEG recording (i.e., by your EEG data acquisition software.).\rCan I use a different half-amplitude cut-off?\r↕\rYes, but be careful with what you\u0026rsquo;re doing, and be sure to read the recommended resources in \u0026ldquo;What should I know about filtering\u0026rdquo; below. For a High-pass filter, you can use anything from 0.01 to 0.1 Hz (half-amplitude). A higher cut-off is better for datasets with more muscle artifacts, whilst if your data is pretty clean you might want to sway closer to 0.05 or 0.01 Hz.\rWhat should I know about filtering?\r↕\rFiltering is a seemingly simple, but actually incredibly complex element of the pre-processing pipeline. It is important that you have a good understanding of what you\u0026rsquo;re doing to your data, and how you can distort it by using the wrong setting. If you are new to filtering, I strongly recommend that you read Steve Luck\u0026rsquo;s chapter Filtering and Fourier Analysis in his 2014 book An Introduction to the Event-Related Potential Technique.\r"},{"id":15,"href":"/erp/docs/table-of-contents/training/part_6/","title":"6. Cleaning your data \u0026 interpolation","section":"ERP Training Resources","content":"\nData cleaning (or \u0026lsquo;help, my data looks a mess\u0026rsquo;)\r#\rIntro\rPreamble: The most important thing to mention here is that there is no substitute for good quality data. You must ensure that the data you collect is the best it possible can be, because there is nothing you can do during pre-processing that can compensate for bad data. That said, even the best data will almost always have periods of noise. Why? because participants are only human. Give them a break in a testing session and they will almost inevitably move more than you thought humanly possible in the space of 30 seconds.\nSo, what should we do, why do we need to clean our data, and what is interpolation? Let\u0026rsquo;s start first with a general walk-through of the data cleaning process.\nVideo\nComing soon\r#\rNow you have a more general idea of what cleaning is and how it works, But there are some important implications of how you choose to clean your data that you may wish to take into consideration at this stage. Select the scenario that best describes your experiment in order to proceed:\nMy study does not include a participant response, or I do not care about filtering my data based on response accuracy\r↕\rThis is possibly the easiest scenario. You can go ahead and clean your dataset as you wish. Try not to remove too many trials unnecessarily (i.e., take into consideration the epoch length so that you don\u0026rsquo;t accidentally cut data too close to the baseline period or end of an epoch and accidentally reject trials).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\n\u0026lt;/div\u0026gt;\rMy study does include a participant response and care about accuracy. The response type is indicated by a trigger in the data\r↕\rThis is also a good scenario. But now you need to be careful. If you remove a period of interest that contains a response trigger, you will no longer have a response for a given trial. If you decide to remove messy data that falls around a condition trigger or response trigger, be sure to remove both triggers to be on the safe side.\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\n\u0026lt;/div\u0026gt;\rMy study does include a participant response and care about accuracy. The response type is indicated in the corresponding log file\r↕\rThis is possibly the most complicated scenario. ow you need to be careful. If you remove a period of interest that contains a response trigger, you will no longer have a response for a given trial. If you decide to remove messy data that falls around a condition trigger or response trigger, be sure to remove both triggers to be on the safe side.\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\n\u0026lt;/div\u0026gt;\rWhilst taking a look at your data, you may notice that certain electrodes that seem particularly noisy (i.e., fuzzy or making unpredictable leaps and falls). If this is the case, you may wish to interpolate them.\nInterpolation - put simply - involves recreating one electrode from its surrounding electrodes.\nActivity\nHave a go at cleaning the dataset provided in ERPLAB. Pay close attention to when the triggers fall, and ensure that you don\u0026rsquo;t unnecessarily remove trials by removing data that falls into the baseline period, or epoch of interest. Make sure you save your file at the end of cleaning so as not to lose your changes.\nFAQ\nQuestion 1\r↕\rAnswer 1.\rQuestion 2\r↕\rAnswer 2.\r"},{"id":16,"href":"/erp/docs/table-of-contents/training/part_7/","title":"7. Run ICA","section":"ERP Training Resources","content":"\nIndependent Component Analysis (ICA) (or \u0026lsquo;what do I do with all these blinks?\u0026rsquo;)\r#\rIntro\nPreamble: This is not the only option for dealing with blinks. Artifact rejection is also a possibility, but will (by definition) reduce the number of trials you have per condition, and trials = power, and with great power comes great papers, or so the old saying goes. However, there are some down sides (see FAQ), so don\u0026rsquo;t be fooled into thinking that ICA is a magic cure with no repercussions.\nWhat does ICA do? In short, ICA creates a model of\u0026hellip;\nVideo Code\nN/A\rScript\nScript #4 (download).\nScript #4 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nQ1\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":17,"href":"/erp/docs/table-of-contents/training/part_8/","title":"8. Re-referencing","section":"ERP Training Resources","content":"\nRe-referencing\r#\rIntro\nImportant distinction between online reference and offline reference. #You should report both in your paper#.\nVideo Code\nEEG = pop_reref( EEG, [REFERENCE CHANNEL/CHANNELS] );\rScript\nScript #5 (download).\nScript #5 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nHow do I choose my offline reference site(s)?\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":18,"href":"/erp/docs/table-of-contents/training/part_9/","title":"9. Low-pass filter (optional)","section":"ERP Training Resources","content":"\nRe-referencing\r#\rIntro\nImportant distinction between online reference and offline reference. #You should report both in your paper#.\nVideo\nComing soon\r#\rCode\nN/A\rScript\nScript #6 (download).\nScript #6 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nQ1\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":19,"href":"/erp/docs/contact/","title":"Contact","section":"Docs","content":"\rContact \u0026amp; info\r#\rEmail: jennifer.lewendon@polyu.edu.hk\nFor any queries about resource content, webpages or any other questions. Personal Website: https://j-lewen.github.io/\nPersonal website with CV, publications \u0026amp; research interests. Google Scholar: https://scholar.google.com/citations?user=oMuNHZoAAAAJ\u0026hl=en\u0026oi=ao\n"},{"id":20,"href":"/erp/docs/table-of-contents/training/part_10/","title":"10. Epoch your data","section":"ERP Training Resources","content":"\nEpoch (or segment, or \u0026lsquo;cut up\u0026rsquo; your data\r#\rIntro\nEpoching effectively cuts up your data into segments based on a given trigger, or set of triggers. So far, we\u0026rsquo;ve worked exclusively with continuous data. What does this mean? This means that your whole EEG recording is in one long \u0026lsquo;continuous\u0026rsquo; file\u0026hellip;\nSee?\nVideo\nComing soon\r#\rCode\nN/A\rScript\nScript #7 (download).\nScript #7 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nHow do I choose my epoch length?\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":21,"href":"/erp/docs/table-of-contents/training/part_11/","title":"11. Artifact rejection","section":"ERP Training Resources","content":"\nTITLE\r#\rIntro\nComing soon\r#\rVideo\nComing soon\r#\rCode\nN/A\rScript\nScript #8 (download).\nScript #8 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nQ1\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":22,"href":"/erp/docs/table-of-contents/training/part_12/","title":"12. Averaging","section":"ERP Training Resources","content":"\nTITLE\r#\rIntro\nComing soon\r#\rVideo\nComing soon\r#\rCode\nN/A\rScript\nScript #9 (download).\nScript #9 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nWhat is the difference between averaging and grand averaging?\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":23,"href":"/erp/docs/table-of-contents/training/part_13/","title":"13. Create difference waves (optional)","section":"ERP Training Resources","content":"\nTITLE\r#\rIntro\nComing soon\r#\rVideo\nComing soon\r#\rCode\nN/A\rScript\nScript #10 (download).\nScript #10 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nQ1\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":24,"href":"/erp/docs/table-of-contents/training/part_14/","title":"14. Grand average","section":"ERP Training Resources","content":"\nTITLE\r#\rIntro\nComing soon\r#\rVideo\nComing soon\r#\rCode\nN/A\rScript\nScript #11 (download).\nScript #11 (view).\nDataset\nTo run this operation via the user interface, the example data set (used in the above video) can be downloaded here\nActivity\nFinally, save your version of the script to your computer so as to ensure you have an up-to-date script for subsequent tutorial sections (and your own data analysis!).\nFAQ\nQ1\r↕\rA1.\rQ2\r↕\rA2.\r"},{"id":25,"href":"/erp/docs/table-of-contents/training/part_15/","title":"15. What next?","section":"ERP Training Resources","content":"\nTITLE\r#\rIntro\nComing soon\r#\rVideo Code\nN/A\rScript\nN/A\rDataset\nActivity\nFAQ\nQ1\r↕\rA1.\rQ2\r↕\rA2.\r"}]